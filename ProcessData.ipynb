{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmhNPn64yN5C"
      },
      "outputs": [],
      "source": [
        "#!pip install langdetect\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import shutil\n",
        "import sys\n",
        "\n",
        "from collections import Counter\n",
        "from langdetect import detect\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import DistilBertTokenizer, DistilBertModel"
      ],
      "metadata": {
        "id": "pf6KqubyyPme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('drive/MyDrive/NLP_Final_Project/dataset/quotes.csv', delimiter=',') # Rohit\n",
        "# dataset = pd.read_csv('drive/MyDrive/NLP/quotes.csv', delimiter=',')\n",
        "nRow, nCol = dataset.shape\n",
        "print(f'There are {nRow} rows and {nCol} columns')"
      ],
      "metadata": {
        "id": "LYV1EfCgyU2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Null Value check\n",
        "print(dataset.isnull().sum())\n",
        "dataset.dropna(inplace=True)\n",
        "dataset.quote.drop_duplicates(inplace=True)\n",
        "\n",
        "# Remove commas from categories. ['Life, Motivation']\n",
        "dataset['category'] = dataset['category'].str.replace(', ', ' ')\n",
        "\n",
        "# Strip extra spaces in category\n",
        "dataset['category'] = dataset['category'].str.strip()\n",
        "dataset['quote'] = dataset['quote'].str.strip()\n",
        "dataset['author'] = dataset['author'].str.strip()\n",
        "\n",
        "# Convert upper case to lower case\n",
        "dataset['category'] = dataset['category'].str.lower()\n",
        "dataset['quote'] = dataset['quote'].str.lower() ## comment if needed\n",
        "dataset['author'] = dataset['author'].str.lower() ## comment if needed"
      ],
      "metadata": {
        "id": "7QNGVlFuyX_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "hci8IH_IyZ9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dictionary to store count for all tags.\n",
        "\n",
        "tags_dict = {}\n",
        "\n",
        "for row in dataset.itertuples():\n",
        "    for cat in row.category.split(' '):\n",
        "        if cat=='':\n",
        "            continue\n",
        "        tags_dict[cat.lower()] = tags_dict.get(cat.lower(), 0) + 1\n",
        "\n",
        "sorted_tags_dict = dict(sorted(tags_dict.items(), key=lambda x: x[1], reverse=True))"
      ],
      "metadata": {
        "id": "I4IpPMhHybhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all the tags whose count is below the specified threshold\n",
        "\n",
        "threshold = 1500\n",
        "\n",
        "tags_to_remove = [key for key, value in sorted_tags_dict.items() if value < threshold]\n",
        "\n",
        "# Remove items from the dictionary\n",
        "for key in tags_to_remove:\n",
        "    del sorted_tags_dict[key]\n",
        "\n",
        "print(f'After removing less frequent tags: there are {len(sorted_tags_dict)} types of different tags')"
      ],
      "metadata": {
        "id": "ZIcw7B5uyiyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of tags to keep\n",
        "top_k = 5\n",
        "tags_to_keep = [tag for tag in list(sorted_tags_dict.keys())[:top_k]]\n",
        "print(f'Top {top_k} tags are {tags_to_keep}')\n",
        "\n",
        "# Remove all the rows where the quote lenght longer than a certain length.\n",
        "\n",
        "min_lenth_threshold = 25\n",
        "max_length_threshold = 256\n",
        "max_len_filtered_dataset = dataset[dataset['quote'].apply(len) <= max_length_threshold].copy()\n",
        "min_len_filtered_dataset = max_len_filtered_dataset[max_len_filtered_dataset['quote'].apply(len) >= min_lenth_threshold].copy()\n",
        "\n",
        "print(f'After removing all quotes greater than length {max_length_threshold} and lesser than length {min_lenth_threshold}, there are {len(dataset)} rows remaining.')\n",
        "\n",
        "min_len_filtered_dataset.head(5)"
      ],
      "metadata": {
        "id": "y7B3mwmRyma6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_len_filtered_dataset['tags'] = min_len_filtered_dataset['category'].apply(lambda x: [tag for tag in tags_to_keep if tag in x.split()])\n",
        "min_len_filtered_dataset['tags'] = min_len_filtered_dataset['tags'].apply(lambda x: '_'.join(x))\n",
        "min_len_filtered_dataset = min_len_filtered_dataset[min_len_filtered_dataset['tags']!='']\n",
        "print(f'Number of rows after removing quote not related to top_k tags : {len(min_len_filtered_dataset)}')"
      ],
      "metadata": {
        "id": "myc29Qwjyrnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# min_len_filtered_dataset['is_eng'] = min_len_filtered_dataset['quote'].apply(lambda x: detect(x)=='en')"
      ],
      "metadata": {
        "id": "ZfV48DRsy5lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_len_filtered_dataset[min_len_filtered_dataset['is_eng'] == False].head(5)"
      ],
      "metadata": {
        "id": "6OfEx88g1GYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_len_filtered_dataset = min_len_filtered_dataset[min_len_filtered_dataset['is_eng'] == True]\n",
        "\n",
        "# min_len_filtered_dataset.to_csv('drive/MyDrive/NLP_Final_Project/dataset/eng_len_filtered_quotes.csv', index=False, encoding='utf-8')"
      ],
      "metadata": {
        "id": "hGqr1WOe1p3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_df = min_len_filtered_dataset.drop(['author','category', 'is_eng'], axis=1)"
      ],
      "metadata": {
        "id": "5N1G3Q6r2A_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = sampled_df\n",
        "\n",
        "df['tags_list'] = df['tags'].str.split('_')\n",
        "\n",
        "tag_counts = Counter(tag for tags_list in df['tags_list'] for tag in tags_list)\n",
        "\n",
        "print('Count of each tag in dataset :')\n",
        "for tag in tag_counts:\n",
        "    print(tag, ':', tag_counts[tag])\n",
        "# tag_counts"
      ],
      "metadata": {
        "id": "kszt0JvZ54TF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_dataframes = {}\n",
        "tags = ['love','life','inspirational', 'philosophy', 'humor']\n",
        "for tag in tags:\n",
        "    sampled_dataframes[tag] = sampled_df[sampled_df['tags'].str.contains(tag)].sample(n=6000, random_state=42)\n",
        "\n",
        "for tag, df in sampled_dataframes.items():\n",
        "    sampled_dataframes[tag] = df.drop_duplicates(subset='quote', keep='first')\n",
        "\n",
        "final_df = pd.concat(sampled_dataframes.values())\n",
        "\n",
        "final_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print('Final Dataset Shape :',final_df.shape)\n",
        "final_df.sample(5)"
      ],
      "metadata": {
        "id": "fNvxoGlq56-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(df, random_seed):\n",
        "\n",
        "  train_val, test_df = train_test_split(df, test_size=0.2, random_state=random_seed, stratify=df['tags'])\n",
        "  train_df, val_df = train_test_split(train_val, test_size=0.15, random_state=random_seed, stratify=train_val['tags'])\n",
        "\n",
        "  for d in [train_df, val_df, test_df]:\n",
        "    tag_count = {}\n",
        "    for tag in d['tags_list']:\n",
        "        for t in tag:\n",
        "        tag_count[t] = tag_count.get(t, 0) + 1\n",
        "    print(tag_count)\n",
        "  return train_df, val_df, test_df"
      ],
      "metadata": {
        "id": "EpGrAjpYG3WP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df['tags_list'] = final_df['tags'].str.split('_')\n",
        "\n",
        "# Count individual tag occurrences\n",
        "tag_counts = Counter(tag for tags_list in final_df['tags_list'] for tag in tags_list)\n",
        "\n",
        "tag_counts"
      ],
      "metadata": {
        "id": "55SOe3q_Gr1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df['tag_count'] = final_df['tags_list'].apply(len)\n",
        "final_df['tag_count'].value_counts()"
      ],
      "metadata": {
        "id": "qaf9vCl6M8U4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-h-1VlyKMIUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u153ildlDort"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}